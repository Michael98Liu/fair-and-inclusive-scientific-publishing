{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and anonymize gender-related data for figure 2\n",
    "\n",
    "This notebook is consisted of two major sections:\n",
    "    \n",
    "- Calculate the percentage of male and female authors, editors, and editors-in-chief (EICs) in each year; jump [there](#Authors,-editors,-and-editors-in-chief-(EICs)).\n",
    "- A randomized baseline model that randomly replaces editors (or EICs) with a randomly selected scientists who may have a different gender but is identical in terms of discipline and academic age, and similar in terms of productivity and impact (both binned into deciles); jump [there](#Randomized-baseline-model).\n",
    "\n",
    "Since the notebook requires huge datasets stored on HPC, **you cannot execute** this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJournalField(df):\n",
    "    df = df.merge(jfield, on='issn')\n",
    "    df = df.merge(topFields.rename(columns={'Discipline':'Field'}), on='Field')\n",
    "    print(df.shape)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def getScientistField(df):\n",
    "    df = df.merge(field_parent, on='NewAuthorId')\n",
    "    df = df.merge(field_name, on='FieldOfStudyId')\n",
    "    print(df.shape)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFull(df, minyear, maxyear):\n",
    "    \n",
    "    dfrange = []\n",
    "    for year in range(df[minyear].min(), df[maxyear].max()+1):\n",
    "        dfrange.append(df[(df[minyear] <= year) & (df[maxyear] >= year)].assign(Year=year))\n",
    "\n",
    "    dfrange = pd.concat(dfrange, sort=False, ignore_index=True)\n",
    "    \n",
    "    return dfrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author info\n",
    "\n",
    "Author gender, year of first publication, and year of last publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120948543, 3)\n",
      "CPU times: user 44.8 s, sys: 9.72 s, total: 54.5 s\n",
      "Wall time: 54.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "author_career = pd.read_csv('/scratch/fl1092/capstone/conflated/AuthorEraDisp.csv',\n",
    "            sep='\\t', memory_map=True,\n",
    "            usecols=['NewAuthorId', 'Yfp', 'Ylp'],\n",
    "            dtype={'NewAuthorId':int, 'Yfp':int, 'Ylp':int, 'Parent':int})\n",
    "assert(author_career.duplicated(subset=['NewAuthorId']).any() == False)\n",
    "print(author_career.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80175966, 4) 74937037\n",
      "(74940548, 4)\n",
      "(74940548, 4) 74937037\n",
      "(74934033, 4) 74934033\n",
      "CPU times: user 1min 51s, sys: 22.7 s, total: 2min 13s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gender = pd.read_csv(\"/scratch/fl1092/capstone/conflated/AllGenders.csv\",sep='\\t',\n",
    "                     usecols=[\"NewAuthorId\",\"gender\",\"confidence\",'count'],\n",
    "                    dtype={\"NewAuthorId\":int,\"gender\":str,\"confidence\":float,'count':int})\n",
    "print(gender.shape, gender.NewAuthorId.nunique())\n",
    "\n",
    "gender = gender.drop_duplicates()\n",
    "print(gender.shape)\n",
    "\n",
    "gender = gender[(gender.confidence >= 0.9) & (gender['count'] >= 10)] # keep confident match only\n",
    "print(gender.shape, gender.NewAuthorId.nunique())\n",
    "\n",
    "gender = gender.drop_duplicates(subset=['NewAuthorId'], keep=False) # a name cannot be both male and female\n",
    "print(gender.shape, gender.NewAuthorId.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74934033, 4)\n",
      "(42831834, 6) 42831834\n",
      "CPU times: user 1min 2s, sys: 18.5 s, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(gender.shape)\n",
    "authors = gender.merge(author_career, on='NewAuthorId')\n",
    "print(authors.shape, authors.NewAuthorId.nunique()) # (42831834, 6) 42831834"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.6 s, sys: 5.53 s, total: 33.1 s\n",
      "Wall time: 33.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "field_name = pd.read_csv(\"/scratch/fl1092/capstone/advanced/FieldsOfStudy.txt\", sep=\"\\t\",\n",
    "                        names = [\"FieldOfStudyId\", \"Rank\", \"NormalizedName\", \"DisplayName\",\n",
    "                                 \"MainType\", \"Level\", \"PaperCount\", \"CitationCount\", \"CreatedDate\"],\n",
    "                       usecols=['FieldOfStudyId','DisplayName']).rename(columns={'DisplayName':'Field'})\n",
    "\n",
    "field_parent = pd.read_csv(\"/scratch/fl1092/capstone/conflated/AuthorFields.csv\",sep='\\t',\n",
    "        usecols=['NewAuthorId', 'Parent'], dtype={'NewAuthorId':int, 'Parent':int}).rename(\n",
    "    columns={'Parent':'FieldOfStudyId'})\n",
    "assert(field_parent.FieldOfStudyId.nunique() == 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topFields = pd.read_csv('../data/supplementary/EditorsGenderTable.csv', sep='\\t', usecols=['Discipline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field of journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4022, 3)\n",
      "(1808, 3)\n",
      "(1808, 5)\n",
      "CPU times: user 73.8 ms, sys: 24.9 ms, total: 98.7 ms\n",
      "Wall time: 98.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "jfield = pd.read_csv('/scratch/fl1092/capstone/bigmem/Elsevier_journal_top_fields.csv',sep='\\t',\n",
    "                     usecols=['issn','Parent','Score'],dtype={'issn':str,'Parent':int,'Score':float})\n",
    "print(jfield.shape)\n",
    "\n",
    "jfield = jfield.assign(issn = jfield.issn.apply(lambda x: '0'*(8-len(x)) + x))\n",
    "\n",
    "jfield =jfield.sort_values(by='Score',ascending=False).drop_duplicates(subset=['issn'],keep='first')\n",
    "print(jfield.shape)\n",
    "\n",
    "jfield = jfield.merge(field_name, left_on='Parent', right_on='FieldOfStudyId')\n",
    "print(jfield.shape)\n",
    "\n",
    "jfield = jfield[['issn','FieldOfStudyId','Field']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors, editors, and editors-in-chief (EICs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.38 s, sys: 2.08 s, total: 11.5 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chiefs = pd.read_csv('/scratch/fl1092/capstone/temp/ChiefAllGender.csv',sep='\\t',\n",
    "                     usecols=['ChiefEditorID','issn','chief_start','chief_end','gender'],\n",
    "                           dtype={'ChiefEditorID':int,'issn':str,'chief_start':int,'chief_end':int,'gender':str})\n",
    "\n",
    "editors = pd.read_csv(\"/scratch/fl1092/capstone/temp/EditorsUnion.csv\",sep='\\t',\n",
    "                      usecols=['ElEditorID','issn','start_year','end_year','gender'],\n",
    "                     dtype={'ElEditorID':int,'issn':str,'start_year':int,'end_year':int,'gender':str})\n",
    "editors = editors[~editors.gender.isna()]\n",
    "\n",
    "authors = pd.read_csv(\"/scratch/fl1092/capstone/temp/AuthorGender.csv\",sep='\\t',\n",
    "                      usecols=['NewAuthorId','Yfp','Ylp','gender'],\n",
    "                     dtype={'NewAuthorId':int,'Yfp':int,'Ylp':int,'gender':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 662 ms, sys: 727 ms, total: 1.39 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "editors = editors.assign(length = editors.end_year - editors.start_year + 1)\n",
    "authors = authors.assign(length = authors.Ylp - authors.Yfp + 1)\n",
    "chiefs = chiefs.assign(length = chiefs.chief_end - chiefs.chief_start + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80926, 6), (4854, 6))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editors.shape, chiefs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Field of authors, editors, and EICs\n",
    "The field of editors (and editors-in-chief) are identified to be the same as the field of the journals they edit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4687, 8)\n",
      "(80776, 8)\n",
      "(42831834, 7)\n",
      "CPU times: user 52.1 s, sys: 15.3 s, total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chiefs = getJournalField(chiefs)\n",
    "editors = getJournalField(editors)\n",
    "authors = getScientistField(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "editors[['gender','Field','length']].to_csv('../data/figure_4/EditorCareerLength.csv',sep='\\t',index=False)\n",
    "chiefs[['gender','Field','length']].to_csv('../data/figure_4/EICCareerLength.csv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider \"career\" length\n",
    "\n",
    "For example, if one female editor serves between 2010 and 2012, another female editor serves between 2010 and 2011, and three male editors serve between 2010 and 2013, we would have:\n",
    "\n",
    "- 2010: female, female, male, male, male (40% female)\n",
    "- 2011: female, female, male, male, male (40% female)\n",
    "- 2012: female, male, male, male (25% female)\n",
    "- 2013: male, male, male (0% female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396991, 9)\n",
      "(156919040, 8)\n",
      "(17687, 9)\n",
      "CPU times: user 1min 2s, sys: 32.6 s, total: 1min 35s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "editor_range = getFull(editors, 'start_year', 'end_year')\n",
    "print(editor_range.shape)\n",
    "\n",
    "author_range = getFull(authors, 'Yfp', 'Ylp')\n",
    "print(author_range.shape)\n",
    "\n",
    "chief_range = getFull(chiefs, 'chief_start', 'chief_end')\n",
    "print(chief_range.shape)\n",
    "\n",
    "# (396991, 10)\n",
    "# (156919040, 11)\n",
    "# (17687, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(df):\n",
    "    df = df.assign(Count=1).groupby(['Year','Field','gender']).Count.sum().reset_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8127, 4)\n",
      "CPU times: user 29.2 s, sys: 15.5 s, total: 44.7 s\n",
      "Wall time: 44.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aut_comp = compress(author_range)\n",
    "print(aut_comp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1751, 4)\n",
      "(1013, 4)\n",
      "CPU times: user 72.7 ms, sys: 2.01 ms, total: 74.7 ms\n",
      "Wall time: 75.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edi_comp = compress(editor_range)\n",
    "print(edi_comp.shape)\n",
    "\n",
    "eic_comp = compress(chief_range)\n",
    "print(eic_comp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "aut_comp.to_csv('../data/figure_4/AuthorGenderCount.csv',sep='\\t',index=False)\n",
    "edi_comp.to_csv('../data/figure_4/EditorGenderCount.csv',sep='\\t',index=False)\n",
    "eic_comp.to_csv('../data/figure_4/ChiefGenderCount.csv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_range[['gender','Field','Year']].to_csv('../data/figure_4/randomBaseline/Editors.csv',sep='\\t',index=False)\n",
    "chief_range[['gender','Field','Year']].to_csv('../data/figure_4/randomBaseline/EICs.csv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.14 s, sys: 6.03 s, total: 11.2 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "author_range = author_range.assign(Age = author_range.Year - author_range.Yfp+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156919040, 8), (120948543, 3))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_range.shape, author_career.shape # (156919040, 12), (120948543, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = list(field_cat.Field.unique())\n",
    "len(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOutComeFreq(df, mapping, outcome, keys):\n",
    "    m = mapping[['Field','Year',outcome,outcome+'Q']].drop_duplicates()\n",
    "    m = m.groupby(['Field', 'Year', outcome+'Q'])[outcome].max().reset_index().rename(columns={outcome:outcome+'Max'})\n",
    "\n",
    "    dfQ = df.merge(m, on=['Field','Year'])\n",
    "    dfQ = dfQ[dfQ[outcome] <= dfQ[outcome+'Max']] # find the minimum quantile that is greater than the value\n",
    "    \n",
    "    dfQ = dfQ.groupby(keys)[outcome+'Q'].min().reset_index()\n",
    "    \n",
    "    df = df.merge(dfQ, on=keys, how='left').fillna(9)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFreq(df, keys):\n",
    "    # df is to be editors (full range)\n",
    "    subs = []\n",
    "    \n",
    "    for year in tqdm(range(1969, 2018)):\n",
    "        sub = df[df.Year == year]\n",
    "        sub = sub.merge(prior_paper[year], on='NewAuthorId', how='left').rename(columns={'Prior':'PriorCite'})\n",
    "        sub = sub.merge(prior_impact[year], on='NewAuthorId', how='left').rename(columns={'Prior':'PriorPub'})\n",
    "        sub = sub.fillna(0)\n",
    "        \n",
    "        mapping = pd.read_csv(f\"/scratch/fl1092/capstone/randomBaseline/binMap/{year}.csv\", sep='\\t',\n",
    "                             dtype={'Field':str,'Year':int,'Age':int,'PriorCite':int,'PriorPub':int,\n",
    "                                    'AgeQ':int,'PriorCiteQ':int,'PriorPubQ':int})\n",
    "        \n",
    "        sub = findOutComeFreq(sub, mapping, 'PriorCite', keys)\n",
    "        sub = findOutComeFreq(sub, mapping, 'PriorPub', keys)\n",
    "        subs.append(sub)\n",
    "        \n",
    "    return pd.concat(subs, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cummulative impact and publication count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bcd42c0e524e77afe77d622d1e6af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 39s, sys: 57.8 s, total: 3min 37s\n",
      "Wall time: 3min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prior_impact = {}\n",
    "for year in tqdm(range(1900, 2019)):\n",
    "    df = pd.read_csv(f'/scratch/fl1092/capstone/conflated/prior_impact/{year}.csv',\n",
    "                                          sep='\\t', memory_map=True,\n",
    "                                          usecols=['NewAuthorId', 'CitationCount'])\n",
    "    df = df.rename(columns={'CitationCount':'Prior'})\n",
    "    prior_impact[year] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64edb6b08f0444fe83fa4561c2c2f820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 59s, sys: 3min 3s, total: 11min 2s\n",
      "Wall time: 11min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prior_paper = {}\n",
    "for year in tqdm(range(1900, 2019)):\n",
    "    df = pd.read_csv(f'/scratch/fl1092/capstone/conflated/prior_paper/{year}.csv',\n",
    "                                          sep='\\t', memory_map=True,\n",
    "                                          usecols=['NewAuthorId', 'PaperCount'])\n",
    "    df = df.rename(columns={'PaperCount':'Prior'})\n",
    "    prior_paper[year] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate quantile bins\n",
    "\n",
    "For each discipline, in each year, find out which quantile bin an outcome value (citation count and publication count) falls into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQuantile(df, outcome):\n",
    "    df = df.sort_values(by=outcome).reset_index(drop=True)\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    if df.shape[0] >= 10:\n",
    "        binSize = int(df.shape[0]/10)+1\n",
    "        df = df.assign(Quantile = (df['index']/binSize).apply(int))\n",
    "        df = df.drop('index', axis=1)\n",
    "        \n",
    "        assert(df.Quantile.max()==9)\n",
    "    else:\n",
    "        df = df.rename(columns={'index':'Quantile'})\n",
    "        print(df.field.unique(), df.Year.unique())\n",
    "    \n",
    "    df = df.rename(columns={'Quantile':outcome+'Q'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrior(df):\n",
    "    for year in tqdm(range(1970, 2018)):\n",
    "        sub = df[df.Year == year]\n",
    "        sub = sub.merge(prior_paper[year], on='NewAuthorId', how='left').rename(columns={'Prior':'PriorCite'})\n",
    "        sub = sub.merge(prior_impact[year], on='NewAuthorId', how='left').rename(columns={'Prior':'PriorPub'})\n",
    "        sub = sub.fillna(0)\n",
    "        sub.to_csv(f\"/scratch/fl1092/capstone/randomBaseline/authorCount/{year}.csv\",sep='\\t',index=False)        \n",
    "        \n",
    "        newsub = []\n",
    "        for field in fields: \n",
    "            f = sub[sub.Field == field]\n",
    "            f = getQuantile(f, 'Age')\n",
    "            f = getQuantile(f, 'PriorCite')\n",
    "            f = getQuantile(f, 'PriorPub')\n",
    "            \n",
    "            f = f[['Field','Year','Age','PriorCite','PriorPub','AgeQ','PriorCiteQ','PriorPubQ']].drop_duplicates()\n",
    "            newsub.append(f)\n",
    "            \n",
    "        newsub = pd.concat(newsub, ignore_index=True, sort=False)\n",
    "        newsub.to_csv(f\"/scratch/fl1092/capstone/randomBaseline/binMap/{year}.csv\",sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "getPrior(author_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editors\n",
    "\n",
    "Find editors' year of first publication, quantiles of cummulative citation and publication count, and field of study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19741, 4), 2017)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editors = pd.read_csv(\"/scratch/fl1092/capstone/elsevier/editors.csv\", sep='\\t',\n",
    "                     usecols=[\"NewAuthorId\", \"issn\", \"start_year\", \"end_year\"],\n",
    "                     dtype={\"NewAuthorId\":int, \"issn\":str, \"start_year\":int, \"end_year\":int})\n",
    "\n",
    "editors.shape, editors.start_year.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19741, 6)\n",
      "CPU times: user 31.1 s, sys: 10.3 s, total: 41.4 s\n",
      "Wall time: 41.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "editors = editors.merge(author_career, on='NewAuthorId')\n",
    "print(editors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "editors = editors.assign(Year = editors.start_year-1)\n",
    "\n",
    "editors = editors.assign(Age = editors.Year - editors.Yfp + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting author's field (19741, 8)\n",
      "(19741, 11)\n",
      "CPU times: user 32 s, sys: 10.1 s, total: 42.1 s\n",
      "Wall time: 42.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "editors = getScientistField(editors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "editors = editors.drop(['FieldOfStudyId'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19741, 7)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit = editors[['NewAuthorId','issn','start_year','end_year','Field','Year','Age']].rename(\n",
    "    columns={'NewAuthorId':'EditorsNewId'})\n",
    "edit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "editQ = getFreq(edit, ['NewAuthorId','issn'])\n",
    "editQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "editQ.to_csv(\"/scratch/fl1092/capstone/randomBaseline/EditorCitationQuantile.csv\",sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EICs\n",
    "\n",
    "Find the field of study, cummulative citation and publication count, and year of first publicaiton of EICs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1356, 5)\n"
     ]
    }
   ],
   "source": [
    "chiefs = pd.read_csv('/scratch/fl1092/capstone/temp/ChiefGender.csv',sep='\\t',\n",
    "                     usecols=['NewAuthorId','issn','chief_start','chief_end','gender'],\n",
    "                           dtype={'NewAuthorId':int,'issn':str,'chief_start':int,'chief_end':int,'gender':str})\n",
    "print(chiefs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1356, 7)\n",
      "CPU times: user 30.5 s, sys: 10.2 s, total: 40.7 s\n",
      "Wall time: 40.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chiefs = chiefs.merge(author_career, on='NewAuthorId')\n",
    "print(chiefs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiefs = chiefs.assign(Year = chiefs.chief_start-1)\n",
    "chiefs = chiefs.assign(Age = chiefs.Year - chiefs.Yfp + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting author's field (1356, 9)\n",
      "(1356, 12)\n",
      "CPU times: user 31.8 s, sys: 10.1 s, total: 41.9 s\n",
      "Wall time: 42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chiefs = getScientistField(chiefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiefs = chiefs.drop(['FieldOfStudyId'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eic = chiefs[['NewAuthorId','issn','chief_start','chief_end','Field','Year','Age']]\n",
    "eic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eicQ = getFreq(eic, ['NewAuthorId','issn'])\n",
    "eicQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eicQ.to_csv(\"/scratch/fl1092/capstone/randomBaseline/EICCitationQuantile.csv\",sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editors find match candidates\n",
    "\n",
    "First step, match editors and authors on field, and age (academic age in a specific year), so that we end up with a smaller sample of authors, of whom we calculate the quantile bins that their citation and publication count falls into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "authorToBeSampled = author_range.merge(edit, on=['Field','Year','Age'])\n",
    "print(authorToBeSampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchedAut = authorToBeSampled[['gender','NewAuthorId','Yfp','Ylp','Field','Year','Age']].drop_duplicates()\n",
    "matchedAut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "autQ = getFreq(matchedAut, ['NewAuthorId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autQ.to_csv(\"/scratch/fl1092/capstone/randomBaseline/AuthorCitationQuantile.csv\",sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EICs find matched candidates\n",
    "\n",
    "First step, match EICs and authors on field, and age (academic age in a specific year). Similar to the previous section; the goal is to end up with a smaller set of authors that could be matched with an EICs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eic = eic.rename(columns={'NewAuthorId':'EditorsNewId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "authorToBeSampled = author_range.merge(eic, on=['Field','Year','Age'])\n",
    "print(authorToBeSampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchedAut = authorToBeSampled[['gender','NewAuthorId','Yfp','Ylp','Field','Year','Age']].drop_duplicates()\n",
    "matchedAut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "autQ = getFreq(matchedAut, ['NewAuthorId'])\n",
    "print(autQ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autQ.to_csv(\"/scratch/fl1092/capstone/randomBaseline/AuthorEICCitationQuantile.csv\",sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editors filter match and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57631018, 7)\n",
      "CPU times: user 20.6 s, sys: 5.31 s, total: 25.9 s\n",
      "Wall time: 26.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "autQ = pd.read_csv(\"/scratch/fl1092/capstone/randomBaseline/AuthorCitationQuantile.csv\",sep='\\t',\n",
    "                   usecols=['gender', 'NewAuthorId', 'Field', 'Year', 'Age', 'PriorCiteQ','PriorPubQ'],\n",
    "                  dtype={'gender':str,'NewAuthorId':int,'Yfp':int,'Ylp':int,'Field':str,'Year':int,\n",
    "                         'Age':int,'PriorCite':int,'PriorPub':int,'PriorCiteQ':int,'PriorPubQ':int})\n",
    "print(autQ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19679, 9)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editQ = pd.read_csv(\"/scratch/fl1092/capstone/randomBaseline/EditorCitationQuantile.csv\",sep='\\t',\n",
    "                    usecols=['NewAuthorId', 'issn', 'start_year', 'end_year', 'Field', 'Year',\n",
    "                             'Age', 'PriorCiteQ','PriorPubQ'],\n",
    "                   dtype={'NewAuthorId':int,'issn':str,'start_year':int,'end_year':int,'Field':str,'Year':int,\n",
    "                         'Age':int,'PriorCite':int,'PriorPub':int,'PriorCiteQ':int,'PriorPubQ':int})\n",
    "editQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "editQ = editQ.rename(columns={'NewAuthorId':'EditorsNewId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22829349, 11)\n",
      "CPU times: user 8.54 s, sys: 4.31 s, total: 12.9 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "toSam = autQ.merge(editQ, on=['Field','Year','Age','PriorCiteQ','PriorPubQ'])\n",
    "print(toSam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22813413, 11)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toSam = toSam[toSam.NewAuthorId != toSam.EditorsNewId]\n",
    "toSam.shape # (22813413, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d623460dbe46d29b823e1c591f18b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 8s, sys: 1min 7s, total: 13min 16s\n",
      "Wall time: 13min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grouped = toSam.groupby(['EditorsNewId','issn','start_year','end_year'])\n",
    "for seed in tqdm(range(50)):\n",
    "    sampled = grouped.sample(1, random_state=seed)\n",
    "    sampled_range = getFull(sampled, 'start_year', 'end_year')[['Field','Year','gender']]\n",
    "    \n",
    "    sampled_range.to_csv(f'../data/figure_4/randomBaseline/editorSampleAgeCitePub/{seed}.csv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EICs filter match and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8492652, 7)\n",
      "CPU times: user 3.3 s, sys: 612 ms, total: 3.92 s\n",
      "Wall time: 3.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "autQ = pd.read_csv(\"/scratch/fl1092/capstone/randomBaseline/AuthorEICCitationQuantile.csv\",sep='\\t',\n",
    "                   usecols=['gender', 'NewAuthorId', 'Field', 'Year', 'Age', 'PriorCiteQ','PriorPubQ'],\n",
    "                  dtype={'gender':str,'NewAuthorId':int,'Yfp':int,'Ylp':int,'Field':str,'Year':int,\n",
    "                         'Age':int,'PriorCite':int,'PriorPub':int,'PriorCiteQ':int,'PriorPubQ':int})\n",
    "print(autQ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1328, 9)\n"
     ]
    }
   ],
   "source": [
    "eicQ = pd.read_csv(\"/scratch/fl1092/capstone/randomBaseline/EICCitationQuantile.csv\",sep='\\t',\n",
    "                  usecols=['NewAuthorId', 'issn', 'chief_start', 'chief_end', 'Field', 'Year',\n",
    "                             'Age', 'PriorCiteQ','PriorPubQ'],\n",
    "                   dtype={'NewAuthorId':int,'issn':str,'chief_start':int,'chief_end':int,'Field':str,'Year':int,\n",
    "                         'Age':int,'PriorCite':int,'PriorPub':int,'PriorCiteQ':int,'PriorPubQ':int})\n",
    "print(eicQ.shape) # 1328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "eicQ = eicQ.rename(columns={'NewAuthorId':'EditorsNewId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1685281, 11)\n",
      "CPU times: user 1.12 s, sys: 246 ms, total: 1.36 s\n",
      "Wall time: 1.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "toSam = autQ.merge(eicQ, on=['Field','Year','Age','PriorCiteQ','PriorPubQ'])\n",
    "print(toSam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1683972, 11)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toSam = toSam[toSam.NewAuthorId != toSam.EditorsNewId]\n",
    "toSam.shape # 1683972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c49c7c6c1f04dbeb105d268021efa00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.7 s, sys: 1.85 s, total: 50.5 s\n",
      "Wall time: 51.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grouped = toSam.groupby(['EditorsNewId','issn','chief_start','chief_end'])\n",
    "for seed in tqdm(range(50)):\n",
    "    sampled = grouped.sample(1, random_state=seed)\n",
    "    sam_range = getFull(sampled, 'chief_start', 'chief_end')[['Field','Year','gender']]\n",
    "    \n",
    "    sam_range.to_csv(f'../data/figure_4/randomBaseline/eicSampleAgeCitePub/{seed}.csv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
